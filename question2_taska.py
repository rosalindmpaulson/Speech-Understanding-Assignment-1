# -*- coding: utf-8 -*-
"""Question2-TaskA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kMk0fXgXSv4J7zujTCDfdQIAD-buyqjE
"""

import librosa
import IPython.display as ipd #to visualize the sound data
import librosa.display
import pandas as pd
import matplotlib.pyplot as plt

#random sample
filename='./UrbanSound8k/audio/fold2/4201-3-3-0.wav'

librosa_audio_data,librosa_sample_rate=librosa.load(filename)
print(librosa_audio_data)

librosa_sample_rate

plt.figure(figsize=(14,5))
librosa.display.waveshow(librosa_audio_data,sr=librosa_sample_rate)
ipd.Audio(filename)

metadata=pd.read_csv('./UrbanSound8k/metadata/UrbanSound8K.csv')
metadata.head(10)

metadata['class'].value_counts()

metadata['fold'].value_counts()

metadata[['fold','class']].value_counts()

# Select the first sample from each (fold, classID) combination
sampled_files = metadata.groupby(['fold', 'classID']).first().reset_index()

# Display the results
sample = sampled_files#[['fold', 'classID', 'slice_file_name']]
sample

import numpy as np
import matplotlib.pyplot as plt
from scipy.io import wavfile

def hann_window(N):
    """Compute the Hann window manually."""
    window = np.zeros(N)
    for n in range(N):
        window[n] = 0.5 * (1 - np.cos((2 * np.pi * n) / (N - 1)))
    return window

def compute_stft(audio, sr, window_type='hann',n_fft=1024, hop_length=512):
    """Compute STFT using a manually implemented Hann window."""

    # Check if audio is stereo and convert to mono if necessary
    if audio.ndim == 2:  # Check if audio has 2 dimensions (stereo)
        audio = np.mean(audio, axis=1)  # Convert to mono by averaging channels

    audio = audio / np.max(np.abs(audio))  # Normalize

    if window_type == 'hann':
        window = hann_window(n_fft)  # Generate Hann window
    elif window_type == 'hamming':
        window = np.hamming(n_fft)
    elif window_type == 'rectangular':
        window = np.ones(n_fft)

    num_frames = 1 + (len(audio) - n_fft) // hop_length  # Number of time steps
    spectrogram = np.zeros((n_fft // 2 + 1, num_frames), dtype=np.complex64)  # STFT matrix

    for i in range(num_frames):
        start = i * hop_length
        end = start + n_fft
        segment = audio[start:end] * window  # Apply Hann window
        fft_result = np.fft.fft(segment)[: n_fft // 2 + 1]  # Compute FFT (first half)
        spectrogram[:, i] = fft_result  # Store FFT result

    magnitude = np.abs(spectrogram) ** 2  # Compute power spectrum
    return 10 * np.log10(magnitude + 1e-10)  # Convert to decibels

def plot_spectrogram(spectrogram, sr, hop_length, title,window_tech):
    """Plot the spectrogram."""
    plt.figure(figsize=(10, 4))
    time_axis = np.linspace(0, len(spectrogram[0]) * hop_length / sr, len(spectrogram[0]))
    freq_axis = np.linspace(0, sr / 2, len(spectrogram))
    plt.pcolormesh(time_axis, freq_axis, spectrogram, shading='gouraud', cmap='viridis')
    plt.colorbar(format='%+2.0f dB')
    plt.title(f'{window_tech.capitalize()}: {title}')
    plt.xlabel('Time (s)')
    plt.ylabel('Frequency (Hz)')
    plt.tight_layout()
    plt.show()

def get_class(df,class_id):
    result = df.loc[df["classID"] == class_id, "class"]
    return result.iloc[0] if not result.empty else "ClassID not found"

# Group by fold and get slice_file_name
for fold, group in sample.groupby("fold"):
    for i in group["slice_file_name"].tolist():
        # Load and process an example WAV file
        file_path = f"./UrbanSound8k/audio/fold{fold}/{i}"
        print(file_path)
        sr, audio = wavfile.read(file_path)

        for window_technique in ['hann','hamming','rectangular']:
            # Compute STFT with
            spectrogram = compute_stft(audio, sr,window_type=window_technique)
            # Plot Spectrogram
            plot_spectrogram(spectrogram, sr, hop_length=512, title=f"Fold {fold}-{get_class(sample,int(i.split('-')[1]))}",window_tech=window_technique)

def get_features(self, audio_file):
        """
        Extract features from an audio file

        Args:
            audio_file (str): path to the audio file

        Returns:
            Numpy array: extracted features
        """
        def array_map(array):
            return [
                    np.min(array),
                    np.max(array),
                    np.median(array),
                    np.mean(array),
                    np.std(array)
                ]

        y, sr = librosa.load(audio_file, sr = None)

        mfcc = librosa.feature.mfcc(y, sr)

        chroma_stft = librosa.feature.chroma_stft(y, sr)

        rms = librosa.feature.rms(y, sr)

        zero = librosa.feature.zero_crossing_rate(y)

        S, phase = librosa.magphase(librosa.stft(y))
        rolloff = librosa.feature.spectral_rolloff(S=S, sr=sr)

        onset_env = librosa.onset.onset_strength(y=y, sr=sr)

        total = np.concatenate((mfcc, chroma_stft, rms, zero, rolloff, np.array([onset_env])), axis=0)
        return np.apply_along_axis(array_map, 1, total).flatten()

